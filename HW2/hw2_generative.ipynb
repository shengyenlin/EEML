{"cells":[{"cell_type":"markdown","metadata":{"id":"AeZtEkZdNMGg"},"source":["## ML HW2 手把手教學 \n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"lMOeb2gcNWdB"},"outputs":[],"source":["import math\n","import os\n","import csv\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["data_path = \"./data/\"\n","path_train = os.path.join(data_path, \"train.csv\")\n","path_test = os.path.join(data_path, \"test.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def load_data(path_train, path_test):\n","    data_train = pd.read_csv(path_train, skipinitialspace = True)\n","    data_test = pd.read_csv(path_test, skipinitialspace = True)\n","    # x_train = pd.read_csv(path_x_train)\n","    # x_test = pd.read_csv(path_x_test)\n","\n","    # x_train = x_train.values\n","    # x_test = x_test.values\n","\n","    # y_train = pd.read_csv(path_y_train, header = None)\n","    # y_train = y_train.values\n","    # y_train = y_train.reshape(-1)\n","    return data_train, data_test"]},{"cell_type":"markdown","metadata":{},"source":["# Data preprocessing\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class DataPreprocessor:\n","    def __init__(self):\n","        self.train_mean = None\n","        self.train_std = None\n","        self.num_cols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n","        self.cat_cols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n","        self.all_native_countries = None\n","\n","    def transform_label(self, data_train):\n","        label_dict = {'<=50K': 0, '>50K': 1}\n","        data_train[\"income\"] = data_train[\"income\"].apply(lambda x: label_dict[x])\n","        return data_train \n","        \n","    def do_one_hot_encoding(self, data_cat: pd.DataFrame, isTraining = False):\n","        if isTraining:\n","            self.all_native_countries = data_cat[\"native_country\"].value_counts().index.sort_values().to_list()\n","            data_one_hot = pd.get_dummies(data_cat)\n","        else:\n","            #fix missing columns in testing dataset\n","            data_cat[\"native_country\"] = data_cat[\"native_country\"].astype(pd.CategoricalDtype(categories=self.all_native_countries))\n","            data_one_hot = pd.get_dummies(data_cat)\n","        return data_one_hot\n","        \n","    def normalize_data(self, X_data: pd.DataFrame, isTraining = False):\n","        if isTraining:\n","            self.train_mean = X_data.mean(axis = 0)\n","            self.train_std = X_data.std(axis = 0)\n","        normalized_data = (X_data - self.train_mean) / self.train_std\n","        return normalized_data\n","\n","    def create_idx(self, data_train):\n","        idx_class1 = data_train[data_train[\"income\"] == 0].index.to_numpy()\n","        idx_class2 = data_train[data_train[\"income\"] == 1].index.to_numpy()\n","        return idx_class1, idx_class2\n","\n","    def preprocess_train_data(self, data_train: pd.DataFrame):\n","        data_train = self.transform_label(data_train)\n","        #split data into numerical columns and categorical columns\n","        data_train_num = data_train[self.num_cols]\n","        data_train_cat = data_train[self.cat_cols]\n","        y_train = np.array(data_train[\"income\"])\n","\n","        #preprocessing - numerical\n","        data_train_num = self.normalize_data(data_train_num, isTraining=True)\n","\n","        #preprocessing - categorical\n","        data_train_cat = self.do_one_hot_encoding(data_train_cat, isTraining=True)\n","\n","        #combine\n","        data_train_preprocessed = pd.concat([data_train_num, data_train_cat], axis = 1)\n","        X_train = np.array(data_train_preprocessed)\n","        \n","        #create observation idx for class1 and class2\n","        idx_class1, idx_class2 = self.create_idx(data_train)\n","        return X_train, y_train, idx_class1, idx_class2\n","\n","    def preprocess_test_data(self, data_test: pd.DataFrame):\n","        #split data into numerical columns and categorical columns\n","        data_test_num = data_test[self.num_cols]\n","        data_test_cat = data_test[self.cat_cols]\n","\n","        #preprocessing - numerical\n","        data_test_num = self.normalize_data(data_test_num, isTraining=False)\n","\n","        #preprocessing - categorical\n","        data_test_cat = self.do_one_hot_encoding(data_test_cat, isTraining=False)\n","\n","        #combine\n","        data_test_preprocessed = pd.concat([data_test_num, data_test_cat], axis = 1)\n","        X_test = np.array(data_test_preprocessed)\n","        return X_test"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\martin\\.conda\\envs\\EEML\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["data_train, data_test = load_data(path_train, path_test)\n","DP = DataPreprocessor()\n","X_train, y_train, idx_class1, idx_class2 = DP.preprocess_train_data(data_train)\n","X_test= DP.preprocess_test_data(data_test)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 1.        , -0.07664587],\n","       [-0.07664587,  1.        ]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["np.cov(X_train.T)[:2, :2]"]},{"cell_type":"markdown","metadata":{"id":"BhRy2oxGRCdC"},"source":["參考 [上課投影片](https://drive.google.com/file/d/1WKjqkJVPIxYh1REbzy6HeoGfZj-mj6NJ/view) P18 and P23\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"SCoUqbnaRKn6"},"outputs":[],"source":["class GenerativeModel:\n","    def __init__(self):\n","        self.mu1 = None\n","        self.mu2 = None\n","        self.sigma1 = None\n","        self.sigma2 = None\n","        self.sigma_share = None\n","        self.num_class1 = None\n","        self.num_class2 = None\n","\n","    def _compute_params(self, X_train, idx_class1, idx_class2):\n","        X_class1 = X_train[idx_class1]\n","        X_class2 = X_train[idx_class2]\n","        self.mu1 = X_class1.mean(axis = 0)\n","        self.mu2 = X_class2.mean(axis = 0)\n","        self.sigma1 = np.cov(X_class1.T)\n","        self.sigma2 = np.cov(X_class2.T)\n","        self.num_class1 = X_class1.shape[0]\n","        self.num_class2 = X_class2.shape[0]\n","        num_observation = X_train.shape[0]\n","        self.sigma_share = (self.num_class1 * self.sigma1 + self.num_class2 * self.sigma2) / num_observation\n","\n","    def _compute_posterior_prob(self, X):\n","        sigma_inverse = np.linalg.inv(self.sigma_share)\n","\n","        w = np.dot( (self.mu1-self.mu2), sigma_inverse)\n","        b = (-0.5) * np.dot(np.dot(self.mu1.T, sigma_inverse), self.mu1) + (0.5) * np.dot(np.dot(self.mu2.T, sigma_inverse), self.mu2) + np.log(float(self.num_class1)/self.num_class2)\n","\n","        z = np.dot(X, w) + b\n","        pred = self._sigmoid(z)\n","        return pred \n","\n","    def _sigmoid(self, z):\n","        res = 1 / (1.0 + np.exp(-z))\n","        return np.clip(res, 1e-6, 1 - (1e-6))\n","\n","    def train(self, X_train, y_train, idx_class1, idx_class2):\n","        self._compute_params(X_train, idx_class1, idx_class2)\n","        y_pred_train = self._compute_posterior_prob(X_train)\n","        y_pred_train = np.round(y_pred_train)\n","        result = (y_pred_train == y_train)\n","        acc = float(result.sum()) / result.shape[0]\n","        print(f\"Training accuracy = {round(acc*100, 3)}%\")\n","        return \n","\n","    def test(self, X_test):\n","        y_pred_test = self._compute_posterior_prob(X_test)\n","        y_pred_test = np.round(y_pred_test)\n","        return y_pred_test"]},{"cell_type":"markdown","metadata":{"id":"EZ5onx1WVWuj"},"source":["# Predict results\n"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"OxVyr8KZVW5u"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training accuracy = 24.081%\n"]}],"source":["GM = GenerativeModel()\n","GM.train(X_train, y_train, idx_class1, idx_class2)\n","y_pred = GM.test(X_test)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"OVEQ1t9o4ahz"},"outputs":[],"source":["def write_to_csv(y_pred, file_name):\n","    path = os.path.join(\"./submission/\", file_name)\n","    with open(path, 'w', newline='') as csvf:\n","        # 建立 CSV 檔寫入器\n","        writer = csv.writer(csvf)\n","        writer.writerow(['id','label'])\n","        for i in range(int(y_pred.shape[0])):\n","            writer.writerow([i + 1, int(y_pred[i])])"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["#記得改名字\n","file_name = 'submission_1023_1.csv'\n","write_to_csv(y_pred, file_name)"]},{"cell_type":"markdown","metadata":{"id":"w3aDCdTxXo-B"},"source":["### Tip for math problem\n","[p1](https://people.eecs.berkeley.edu/~jrs/189/exam/mids14.pdf)  \n","[p2&3](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf)  \n","[p3](https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ML_HW2_generative.ipynb","provenance":[]},"interpreter":{"hash":"853a6c1de715781c4e36e93313002732d37040606184d41a7b9ff831089b66e5"},"kernelspec":{"display_name":"Python 3.7.10 64-bit ('EEML': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}
